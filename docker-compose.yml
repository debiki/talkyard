version: '3.7'

networks:
  internal_net:
    driver: bridge
    ipam:
      config:
        - subnet: ${INTERNAL_NET_SUBNET}

services:
  web:
    build: images/web/
    image: ${DOCKER_REPOSITORY}/talkyard-web
    # so can specify core dump path [NGXCORED]
    #privileged: true
    volumes:
      # Mount the Lua and JS and CSS scripts, rather than relying on Docker's COPY,
      # so Nginx can auto reload them after edits, without rebuilding the image.
      # (The files are COPY:d too, so will work in Prod.)
      - ./images/web/ed-lua/:/opt/talkyard/lua/:ro
      - ./images/web/assets/:/opt/talkyard/assets/:ro   # [NGXSTC]
      - ./images/web/ty-media/:/opt/talkyard/ty-media/:ro
      - ./volumes/uploads/:/opt/talkyard/uploads/:ro
      - ./volumes/letsencrypt/:/etc/letsencrypt/:ro
      - ./volumes/nginx-logs/:/var/log/nginx/
      - ./volumes/nginx-core-dumps/:/tmp/cores/
    ports:
      - '80:80'
      - '443:443'
    networks:
      internal_net:
        ipv4_address: ${INTERNAL_NET_WEB_IP}
    depends_on:
      - app
      #- cache [NCHANREDIS]
    environment:
      #TY_NGX_LIMIT_REQ_BODY_SIZE: "5m"
      CDN_PULL_KEY: "public"
      # This is dev mode; tell the browser to refresh its cache each request. [2WBKP46]
      TY_MAX_AGE_YEAR: "no-cache"
      TY_MAX_AGE_MONTH: "no-cache"
      TY_MAX_AGE_WEEK: "no-cache"
      TY_MAX_AGE_DAY: "no-cache"

  app:
    build:
      context: images/app/
      dockerfile: Dockerfile.dev
    # (Image ${DOCKER_REPOSITORY}/talkyard-app is for production, and gets created by
    # ./docker/build-app-prod.sh.)
    image: ${DOCKER_REPOSITORY}/talkyard-app-dev
    stdin_open: true  # otherwise Play exits
    tty: true  # colored logs
    volumes:
      - ./:/opt/talkyard/app/
      - ./volumes/uploads/:/opt/talkyard/uploads/
      - ./volumes/app-logs/:/var/log/talkyard/
      # So assets get refreshed on restart, in dev mode, without rebuilding image. [APPJSPATH]
      - ./images/app/assets/:/opt/talkyard/app/assets/:ro
      - ./version.txt:/opt/talkyard/app/version.txt:ro
      # Without this, takes forever to start: sbt would always download all dependencies. [SBTHOME]
      # This is for Linux:  (https://get-coursier.io/docs/cache.html#default-location)
      - ${HOME}/.coursier/:/home/owner/.coursier/
      #
      # This won't work:
      # - ${HOME}/.cache/.coursier/:/home/owner/.cache/.coursier/
      # seems to always cause:
      #       [warn] scala-library-2.12.8.jar no longer exists at /home/owner/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/scala-library/2.12.8/scala-library-2.12.8.jar
      #       bash: tput: command not found
      #       [info] Updating
      #       [info] Resolved  dependencies
      #       [error] java.nio.file.AccessDeniedException: /home/owner/.cache/coursier/v1
      #       [error] 	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
      #       [error] 	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
      #       [error] 	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
      #       [error] 	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
      #       [error] 	at java.nio.file.Files.createDirectory(Files.java:674)
      #       [error] 	at java.nio.file.Files.createAndCheckIsDirectory(Files.java:781)
      #       [error] 	at java.nio.file.Files.createDirectories(Files.java:767)
      #       [error] 	at lmcoursier.internal.shaded.coursier.paths.Util.createDirectories(Util.java:64)
      #       [error] 	at lmcoursier.internal.shaded.coursier.paths.CachePath.withStructureLock(CachePath.java:128)
      #       [error] 	at lmcoursier.internal.shaded.coursier.cache.CacheLocks$.withStructureLock(CacheLocks.scala:22)
      #       [error] 	at lmcoursier.internal.shaded.coursier.cache.CacheLocks$.withLockOr(CacheLocks.scala:39)
      #       [error] 	at lmcoursier.internal.shaded.coursier.cache.FileCache.$anonfun$download$32(FileCache.scala:508)
      #       [error] 	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
      # This works:
      - ${HOME}/.cache/:/home/owner/.cache/
      #
      #
      - ${HOME}/.ivy2/:/home/owner/.ivy2/
      - ${HOME}/.sbt/:/home/owner/.sbt/
    networks:
      internal_net:
        ipv4_address: ${INTERNAL_NET_APP_IP}
    ports:
      # Let's expose these, for debugging and troubleshooting.
      - '9000:9000' # Play's HTTP listen port.
      - '9999:9999' # Java debugger port
      - '3333:3333' # JMX
    depends_on:
      - cache
      - rdb
      - search
      - fakemail
    environment:
      PLAY_HEAP_MEMORY_MB: 2800
      HOSTNAME: "localhost"
      CREATE_SITE_HOSTNAME: "localhost"
      BECOME_OWNER_EMAIL_ADDRESS: "admin@example.com"
      E2E_TEST_PASSWORD: "public"
      FORBIDDEN_PASSWORD: "public"

      # ----- Tracing
      # See: https://github.com/jaegertracing/legacy-client-java/blob/master/jaeger-core/README.md
      #         #configuration-via-environment

      # Or "probabilistic", param 0.0 ... 1.0, or "ratelimiting" with param = num samples per second.
      # or "remote" (the default), asks the Jaeger agent how to sample.
      JAEGER_SAMPLER_TYPE: "const"
      JAEGER_SAMPLER_PARAM: "1"
      # Or 6831? 6832? will be renamed to JAEGER_CONFIG_MANAGER_HOST_PORT
      # https://github.com/jaegertracing/jaeger-client-go/issues/282
      #JAEGER_SAMPLER_MANAGER_HOST_PORT: "tracer:5778"

      # Either configure Jaeger agent host and port:
      # JAEGER_AGENT_HOST
      # JAEGER_AGENT_PORT
      # Or connect directly to the Jaeger connector: (optionally with authentication info)
      JAEGER_ENDPOINT: "http://tracer:14268/api/traces"
      # JAEGER_USER: ""
      # JAEGER_PASSWORD: ""
      # JAEGER_AUTH_TOKEN: ""

  cache:
    build: images/cache/
    image: ${DOCKER_REPOSITORY}/talkyard-cache
    volumes:
      - ./volumes/cache-data/:/data/
    # Expose, so can troubleshoot-query Redis.
    ports:
      - '6379:6379'
    networks:
      internal_net:
        ipv4_address: ${INTERNAL_NET_CACHE_IP}
    sysctls:
      net.core.somaxconn: 511

  search:
    build: images/search/
    image: ${DOCKER_REPOSITORY}/talkyard-search
    # If too low, the 'search' container will suddenly exit with code 137. No error message
    # will get logged â€” instead it just exits, suddenly. Why? OOM-killed? In Docker? Hmm.
    #mem_limit: 800M
    volumes:
      - ./volumes/search-data/:/usr/share/elasticsearch/data/
      - ./volumes/search-logs/:/usr/share/elasticsearch/logs/
    ports:
      # Expose, for troubleshooting.
      - '9200:9200'
      - '9300:9300'
    networks:
      internal_net:
        ipv4_address: ${INTERNAL_NET_SEARCH_IP}
    environment:
      ES_JAVA_OPTS: '-Xms384m -Xmx384m'

  rdb:
    build: images/rdb/
    image: ${DOCKER_REPOSITORY}/talkyard-rdb
    volumes:
      - ./volumes/rdb-data/:/var/lib/postgresql/data/
      - ./volumes/rdb-logs/:/var/log/postgresql/
    networks:
      internal_net:
        ipv4_address: ${INTERNAL_NET_RDB_IP}
    environment:
      POSTGRES_PASSWORD: 'public'
      PEER_HOST: 'rdb2'
      PEER_PORT: '5432'
      PEER_PASSWORD: 'public2'
      CREATE_TEST_USER: 'yes'

  # An extra database, so you can experiment with Postgres replication and failover.
  # You don't need to start it.
  #rdb2:
  #  mem_limit: 30M
  #  build: images/rdb/
  #  volumes:
  #    - ./volumes/rdb2-data/:/var/lib/postgresql/data/
  #    - ./volumes/rdb2-logs/:/var/log/postgresql/
  #  networks:
  #    internal_net:
  #      ipv4_address: ${INTERNAL_NET_RDB2_IP}
  #  environment:
  #    POSTGRES_PASSWORD: 'public2'
  #    PEER_HOST: 'rdb'
  #    PEER_PORT: '5432'
  #    PEER_PASSWORD: 'public'

  test:
    build: images/gulp/
    image: ${DOCKER_REPOSITORY}/talkyard-test
    volumes:
      - ./:/opt/talkyard/server/
    ports:
      # This is for debugging tests running in Node.js in this container, and started
      # via `node --debug-brk --inspect=9229`. [8EA02R4]
      - '9229:9229'
    networks:
      internal_net:
        ipv4_address: ${INTERNAL_NET_TEST_IP}
    # So can send HTTP request to the web container. See tests/security/settings.ts [7PKW4R2]
    depends_on:
      - web
    # Don't want this container to start at all by default.
    command: 'exit 0'

  # Dummy SMTP server, for testing.
  fakemail:
    build: images/fakemail/mailslurper
    image: ${DOCKER_REPOSITORY}/fakemail
    volumes:
      - ./images/fakemail/mailslurper-config.json:/config.json
      - ./images/fakemail/fakemail-publ-test-self-signed.key:/smtp-server.key
      - ./images/app/fakemail-publ-test-self-signed.crt:/smtp-server.crt  # yes, in app-dev [26UKWD2]
    ports:
     - '8025:8025'  # smtp, '80' + 25 (25 = old standard port, 587 = new for STARTTLS)
     - '8026:8026'  # admin interface,  '80' + 25 + 1
     - '8027:8027'  # service port = api requests or what? '80' + 25 + 2
    networks:
      internal_net:
        ipv4_address: ${INTERNAL_NET_FAKEMAIL_IP}

  # Jaeger Tracing. Access at http://localhost:16686.
  tracer:
    image: jaegertracing/all-in-one:1.7
    ports:               # Component. What. (https://www.jaegertracing.io/docs/1.6/getting-started/)
      #- '5775:5775/udp' # Agent. accept zipkin.thrift over compact thrift protocol
      - '6831:6831/udp'  # Agent. accept jaeger.thrift over compact thrift protocol
      - '6832:6832/udp'  # Agent. accept jaeger.thrift over binary thrift protocol
      - '5778:5778'      # Agent. serve configs
      - '16686:16686'    # Query. Web interface + find traces.
      - '14268:14268'    # Collector. accept jaeger.thrift directly from clients
      #- '9411:9411'     # Collector. Zipkin compatible endpoint
    networks:
      internal_net:
        ipv4_address: ${INTERNAL_NET_TRACER_IP}

  # The same as the 'test' container, except that 'gulp' won't start the rest of the stack,
  # instead it just transpiles Typescript and Stylus.
  gulp:
    build: images/gulp/
    image: ${DOCKER_REPOSITORY}/talkyard-gulp
    tty: true  # colored logs
    volumes:
      - ./:/opt/talkyard/server/   # [NODEHOME]
    command: ['yarn install && gulp watch']

  # Would like to remove, but is incl in talkyard-prod-one's Compose file already,
  # and would cause errors, if removed here, and people then upgrade? (because new version
  # couldn't be downloaded). Remove, when releasing the next major talkyard-prod-one version
  # and peopl have upgraded?
  certgen:
    build: images/certgen/
    image: ${DOCKER_REPOSITORY}/talkyard-certgen
    # Only want to build (but not run) this container, in dev/test mode.
    command: 'echo'

# vim: et ts=2 sw=2
